import os
from tensorflow.keras.models import model_from_json
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate
from tensorflow.keras.models import Model
from tensorflow.keras.layers import BatchNormalization
from tensorflow.keras.layers import MaxPooling2D, AveragePooling2D
from tensorflow.keras.layers import Concatenate
from tensorflow.keras.layers import Lambda, Flatten, Dense
from tensorflow.keras.initializers import glorot_uniform
from tensorflow.keras.layers import Layer
from tensorflow.keras import backend as K
K.set_image_data_format('channels_last')
import os
import numpy as np
from numpy import genfromtxt
import pandas as pd
import tensorflow as tf
import PIL

model_json = os.path.expanduser('downloads/model.json')
model_path = os.path.expanduser('downloads/facenet_keras_weights.h5')
json_file = open(model_json, 'r')
loaded_model_json = json_file.read()
json_file.close()
model = model_from_json(loaded_model_json)
model.load_weights(model_path)

def img_to_encoding(image, model):
    img = np.around(np.array(img) / 255.0, decimals=12)
    x_train = np.expand_dims(img, axis=0)
    embedding = model.predict_on_batch(x_train)
    return embedding / np.linalg.norm(embedding, ord=2)

def recognize(image, database, model):
    encoding =  img_to_encoding(image,model)
    min_dist = 1000000
    identity = 'unknown'
    for (name, db_enc) in database.items():
        dist = np.linalg.norm(encoding-db_enc)
        if min_dist > dist:
            min_dist = dist
            identity = name
    if min_dist > 0.7:
        identity = 'unknown'
        
    return min_dist, identity

def add(image,database,model,name):
    if name in database:
        return
    embeeding = img_to_embeeding(image,model)
    database[name] = embeeding
    return
